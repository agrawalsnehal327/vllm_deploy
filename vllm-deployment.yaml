apiVersion: v1
kind: Pod
metadata:
  name: gpt-oss-20b
  labels:
    app: gpt-oss-20b
spec:
  restartPolicy: Never
  containers:
  - name: gpt-oss-20b
    image: vllm/vllm-openai:gptoss
    args:
      - "--model"
      - "openai/gpt-oss-20b"
      - "--host"
      - "0.0.0.0"
      - "--port"
      - "8000"
      - "--trust-remote-code"
    env:
      - name: NVIDIA_VISIBLE_DEVICES
        value: "2,3"   # use GPUs 2 and 3
      - name: TORCH_CUDA_ARCH_LIST
        value: "9.0"    # adjust for your GPU arch
    ports:
      - containerPort: 8000
    resources:
      limits:
        nvidia.com/gpu: 2
      requests:
        nvidia.com/gpu: 2
        cpu: "6"
        memory: "64Gi"
---
apiVersion: v1
kind: Service
metadata:
  name: gpt-oss-20b-service
spec:
  selector:
    app: gpt-oss-20b
  ports:
    - name: http
      protocol: TCP
      port: 8000
      targetPort: 8000
  type: NodePort
